{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 光流\n",
    "\n",
    "光流会通过查看*相同的*点从一个图像帧移动到下一个图像帧的位置来跟踪对象。接下来，让我们加载一些类似pacman人脸的示例帧，并使其向右和向下移动，然后看一看光流如何找到描述人脸运动的**运动矢量**！\n",
    "\n",
    "与之前一样，首先，导入资源并读入图像。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.image as mpimg  # for reading in images\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2  # computer vision library\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Read in the image frames\n",
    "frame_1 = cv2.imread('images/pacman_1.png')\n",
    "frame_2 = cv2.imread('images/pacman_2.png')\n",
    "frame_3 = cv2.imread('images/pacman_3.png')\n",
    "\n",
    "# convert to RGB\n",
    "frame_1 = cv2.cvtColor(frame_1, cv2.COLOR_BGR2RGB)\n",
    "frame_2 = cv2.cvtColor(frame_2, cv2.COLOR_BGR2RGB)\n",
    "frame_3 = cv2.cvtColor(frame_3, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "\n",
    "# Visualize the individual color channels\n",
    "f, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(20,10))\n",
    "ax1.set_title('frame 1')\n",
    "ax1.imshow(frame_1)\n",
    "ax2.set_title('frame 2')\n",
    "ax2.imshow(frame_2)\n",
    "ax3.set_title('frame 3')\n",
    "ax3.imshow(frame_3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 寻找跟踪点\n",
    "\n",
    "在使用光流之前，我们必须给它一组用来跟踪两个图像帧的*关键点*！\n",
    "\n",
    "在下面的例子中，我们要用到**Shi-Tomasi角点检测器**，这个检测器会使用与Harris角点检测器相同的过程来查找构成图像中“角点”的强度模式，只是它添加了一个额外的参数来帮助选择最突出的角点。你可以在 [这个文档](https://docs.opencv.org/3.0-beta/doc/py_tutorials/py_feature2d/py_shi_tomasi/py_shi_tomasi.html)中阅读有关此检测算法的更多信息。\n",
    "\n",
    "或者，你也可以选择使用Harris甚至ORB来查找特征点。我发现这两种方法也很有效。\n",
    "\n",
    "**你可以看到检测到的点出现在人脸的角点处。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for ShiTomasi corner detection\n",
    "feature_params = dict( maxCorners = 10,\n",
    "                       qualityLevel = 0.2,\n",
    "                       minDistance = 5,\n",
    "                       blockSize = 5 )\n",
    "\n",
    "\n",
    "# convert all frames to grayscale\n",
    "gray_1 = cv2.cvtColor(frame_1, cv2.COLOR_RGB2GRAY)\n",
    "gray_2 = cv2.cvtColor(frame_2, cv2.COLOR_RGB2GRAY)\n",
    "gray_3 = cv2.cvtColor(frame_3, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "\n",
    "# Take first frame and find corner points in it\n",
    "pts_1 = cv2.goodFeaturesToTrack(gray_1, mask = None, **feature_params)\n",
    "\n",
    "# display the detected points\n",
    "plt.imshow(frame_1)\n",
    "for p in pts_1:\n",
    "    # plot x and y detected points\n",
    "    plt.plot(p[0][0], p[0][1], 'r.', markersize=15)\n",
    "\n",
    "# print out the x-y locations of the detected points\n",
    "print(pts_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 执行光流\n",
    "\n",
    "在你感兴趣的初始图像上检测到关键点之后，就可以使用OpenCV的`calcOpticalFlowPyrLK`计算此图像帧（第1帧）和下一帧（第2帧）之间的光流。其中，`calcOpticalFlowPyrLK`可以在[这里](https://docs.opencv.org/trunk/dc/d6b/group__video__track.html#ga473e4b886d0bcc6b65831eb88ed93323) 找到。它会接收初始图像帧、下一张图像和第一组点，并返回下一帧中检测到的点和一个值，该值表示的是从一帧到下一帧之间的点匹配程度。\n",
    "\n",
    "参数还包括窗口大小和maxLevels，它们分别表示窗口的大小以及将使用金字塔缩放比例缩放给定图像的级别数。此版本会对匹配点进行迭代搜索，此匹配条件则反映在最后一个参数中。如果使用其他图像，则可能需要更改这些值，但更改的值应适用于提供的示例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for lucas kanade optical flow\n",
    "lk_params = dict( winSize  = (5,5),\n",
    "                  maxLevel = 2,\n",
    "                  criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "\n",
    "# calculate optical flow between first and second frame\n",
    "pts_2, match, err = cv2.calcOpticalFlowPyrLK(gray_1, gray_2, pts_1, None, **lk_params)\n",
    "\n",
    "# Select good matching points between the two image frames\n",
    "good_new = pts_2[match==1]\n",
    "good_old = pts_1[match==1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，让我们把生成的运动矢量显示出来吧！你应该看到第一个图像上绘有运动矢量，该运动矢量表示的是从第一帧到下一帧的运动方向。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a mask image for drawing (u,v) vectors on top of the second frame\n",
    "mask = np.zeros_like(frame_2)\n",
    "\n",
    "# draw the lines between the matching points (these lines indicate motion vectors)\n",
    "for i,(new,old) in enumerate(zip(good_new,good_old)):\n",
    "    a,b = new.ravel()\n",
    "    c,d = old.ravel()\n",
    "    # draw points on the mask image\n",
    "    mask = cv2.circle(mask,(a,b),5,(200),-1)\n",
    "    # draw motion vector as lines on the mask image\n",
    "    mask = cv2.line(mask, (a,b),(c,d), (200), 3)\n",
    "    # add the line image and second frame together\n",
    "\n",
    "composite_im = np.copy(frame_2)\n",
    "composite_im[mask!=0] = [0]\n",
    "\n",
    "plt.imshow(composite_im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: 在图像帧2和3之间执行光流\n",
    "\n",
    "重复此过程，但只应用于最后两个图像帧，看一看生成的运动矢量是什么样的。想象一下，将这个过程应用于一系列图像帧，并绘制某个给定对象的整个运动路径。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Perform optical flow between image frames 2 and 3\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
